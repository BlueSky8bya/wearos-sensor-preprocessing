{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"16z_ULJAtGN0aLLT5Q9lQkQGdpxTEBygK","authorship_tag":"ABX9TyNb2hvKFvm7f2AXWa5e4bnW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"tUDyzrZJe8Dz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759447201714,"user_tz":-540,"elapsed":120049,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}},"outputId":"64594f59-23bf-48a0-806b-6ca4d23a4410"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!git clone https://github.com/pickus91/HRV.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QewCWZR1XWzI","executionInfo":{"status":"ok","timestamp":1759447224519,"user_tz":-540,"elapsed":746,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}},"outputId":"2dd619cc-61ca-4dc2-ad70-6edeff49e3be"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'HRV'...\n","remote: Enumerating objects: 250, done.\u001b[K\n","remote: Counting objects: 100% (250/250), done.\u001b[K\n","remote: Compressing objects: 100% (116/116), done.\u001b[K\n","remote: Total 250 (delta 126), reused 250 (delta 126), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (250/250), 3.11 MiB | 29.49 MiB/s, done.\n","Resolving deltas: 100% (126/126), done.\n"]}]},{"cell_type":"code","source":["!cat /content/HRV/timeDomain.py\n","!cat /content/HRV/frequencyDomain.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kP_Tky2gbCUN","executionInfo":{"status":"ok","timestamp":1759447224715,"user_tz":-540,"elapsed":195,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}},"outputId":"85ca51e9-4913-4ade-8fb3-f0a4b4328a72"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Mar  1 13:59:24 2017\n","\n","@author: picku\n","\"\"\"\n","\n","import numpy as np\n","\n","def timeDomain(NN):\n","    \n","    L = len(NN)    \n","    ANN = np.mean(NN)\n","    SDNN = np.std(NN)\n","    SDSD = np.std(np.diff(NN))    \n","    NN50 = len(np.where(np.diff(NN) > 0.05)[0])    \n","    pNN50 = NN50/L    \n","    NN20 = len(np.where(np.diff(NN) > 0.02)[0])\n","    pNN20 = NN20/L\n","    rMSSD = np.sqrt((1/L) * sum(np.diff(NN) ** 2))        \n","    MedianNN = np.median(NN)\n","    \n","    timeDomainFeats = {'ANN': ANN, 'SDNN': SDNN,\n","                       'SDSD': SDSD, 'NN50': NN50,\n","                       'pNN50': pNN50, 'NN20': NN20,\n","                       'pNN20': pNN20, 'rMSSD': rMSSD,\n","                       'MedianNN':MedianNN}\n","                       \n","    return timeDomainFeats# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Mar  3 12:08:40 2017\n","\n","@author: picku\n","\n","\"\"\"\n","import numpy as np\n","from scipy import interpolate, signal\n","import matplotlib.pyplot as plt\n","from matplotlib import style\n","style.use('ggplot')\n","import matplotlib.patches as mpatches\n","from collections import OrderedDict\n","\n","def frequencyDomain(RRints, band_type = None, lf_bw = 0.11, hf_bw = 0.1, plot = 0):\n","    \"\"\" Computes frequency domain features on RR interval data\n","    \n","    Parameters:\n","    ------------\n","    RRints : list, shape = [n_samples,]\n","           RR interval data\n","    \n","    band_type : string, optional\n","             If band_type = None, the traditional frequency bands are used to compute \n","             spectral power:\n","           \n","                 LF: 0.003 - 0.04 Hz\n","                 HF: 0.04 - 0.15 Hz\n","                 VLF: 0.15 - 0.4 Hz           \n","           \n","             If band_type is set to 'adapted', the bands are adjusted according to \n","             the protocol laid out in:\n","           \n","             Long, Xi, et al. \"Spectral boundary adaptation on heart rate \n","             variability for sleep and wake classification.\" International \n","             Journal on Artificial Intelligence Tools 23.03 (2014): 1460002. \n","                        \n","    lf_bw : float, optional\n","          Low frequency bandwidth centered around LF band peak frequency\n","          when band_type is set to 'adapted'. Defaults to 0.11\n","             \n","    hf_bw : float, optional\n","          High frequency bandwidth centered around HF band peak frequency\n","          when band_type is set to 'adapted'. Defaults to 0.1\n","          \n","    plot : int, 1|0\n","          Setting plot to 1 creates a matplotlib figure showing frequency\n","          versus spectral power with color shading to indicate the VLF, LF,\n","          and HF band bounds.\n","    \n","    Returns:\n","    ---------\n","    freqDomainFeats : dict\n","                   VLF_Power, LF_Power, HF_Power, LF/HF Ratio              \n","    \"\"\"\n","\n","    #Remove ectopic beats\n","    #RR intervals differing by more than 20% from the one proceeding it are removed\n","    NNs = []\n","    for c, rr in enumerate(RRints):        \n","        if abs(rr - RRints[c-1]) <= 0.20 * RRints[c-1]:\n","            NNs.append(rr)\n","      \n","    #Resample @ 4 Hz\n","    fsResamp = 4   \n","    tmStamps = np.cumsum(NNs) #in seconds \n","    f = interpolate.interp1d(tmStamps, NNs, 'cubic')\n","    tmInterp = np.arange(tmStamps[0], tmStamps[-1], 1/fsResamp)\n","    RRinterp = f(tmInterp)          \n","    \n","    #Remove DC component     \n","    RRseries = RRinterp - np.mean(RRinterp)\n","        \n","    #Pwelch w/ zero pad     \n","    fxx, pxx = signal.welch(RRseries, fsResamp, nfft = 2**14, window = 'hann')    \n","    \n","    vlf= (0.003, 0.04)\n","    lf = (0.04, 0.15)\n","    hf = (0.15, 0.4)\n","    \n","    plot_labels = ['VLF', 'LF', 'HF']\n","        \n","    if band_type == 'adapted':     \n","            \n","        vlf_peak = fxx[np.where(pxx == np.max(pxx[np.logical_and(fxx >= vlf[0], fxx < vlf[1])]))[0][0]] \n","        lf_peak = fxx[np.where(pxx == np.max(pxx[np.logical_and(fxx >= lf[0], fxx < lf[1])]))[0][0]]\n","        hf_peak = fxx[np.where(pxx == np.max(pxx[np.logical_and(fxx >= hf[0], fxx < hf[1])]))[0][0]]\n","    \n","        peak_freqs =  (vlf_peak, lf_peak, hf_peak) \n","            \n","        hf = (peak_freqs[2] - hf_bw/2, peak_freqs[2] + hf_bw/2)\n","        lf = (peak_freqs[1] - lf_bw/2, peak_freqs[1] + lf_bw/2)   \n","        vlf = (0.003, lf[0])\n","        \n","        if lf[0] < 0:\n","            print('***Warning***: Adapted LF band lower bound spills into negative frequency range')\n","            print('Lower thresold of LF band has been set to zero')\n","            print('Adjust LF and HF bandwidths accordingly')\n","            lf = (0, lf[1])        \n","            vlf = (0, 0)\n","        elif hf[0] < 0:\n","            print('***Warning***: Adapted HF band lower bound spills into negative frequency range')\n","            print('Lower thresold of HF band has been set to zero')\n","            print('Adjust LF and HF bandwidths accordingly')\n","            hf = (0, hf[1])        \n","            lf = (0, 0)        \n","            vlf = (0, 0)\n","            \n","        plot_labels = ['Adapted_VLF', 'Adapted_LF', 'Adapted_HF']\n","\n","    df = fxx[1] - fxx[0]\n","    vlf_power = np.trapz(pxx[np.logical_and(fxx >= vlf[0], fxx < vlf[1])], dx = df)      \n","    lf_power = np.trapz(pxx[np.logical_and(fxx >= lf[0], fxx < lf[1])], dx = df)            \n","    hf_power = np.trapz(pxx[np.logical_and(fxx >= hf[0], fxx < hf[1])], dx = df)             \n","    totalPower = vlf_power + lf_power + hf_power\n","    \n","    #Normalize and take log\n","    vlf_NU_log = np.log((vlf_power / (totalPower - vlf_power)) + 1)\n","    lf_NU_log = np.log((lf_power / (totalPower - vlf_power)) + 1)\n","    hf_NU_log = np.log((hf_power / (totalPower - vlf_power)) + 1)\n","    lfhfRation_log = np.log((lf_power / hf_power) + 1)   \n","    \n","    freqDomainFeats = {'VLF_Power': vlf_NU_log, 'LF_Power': lf_NU_log,\n","                       'HF_Power': hf_NU_log, 'LF/HF': lfhfRation_log}\n","                       \n","    if plot == 1:\n","        #Plot option\n","        freq_bands = {'vlf': vlf, 'lf': lf, 'hf': hf}\n","        freq_bands = OrderedDict(sorted(freq_bands.items(), key=lambda t: t[0]))\n","        colors = ['lightsalmon', 'lightsteelblue', 'darkseagreen']\n","        fig, ax = plt.subplots(1)\n","        ax.plot(fxx, pxx, c = 'grey')\n","        plt.xlim([0, 0.40])\n","        plt.xlabel(r'Frequency $(Hz)$')\n","        plt.ylabel(r'PSD $(s^2/Hz$)')\n","        \n","        for c, key in enumerate(freq_bands):\n","            ax.fill_between(fxx[min(np.where(fxx >= freq_bands[key][0])[0]): max(np.where(fxx <= freq_bands[key][1])[0])],\n","                            pxx[min(np.where(fxx >= freq_bands[key][0])[0]): max(np.where(fxx <= freq_bands[key][1])[0])],\n","                            0, facecolor = colors[c])\n","            \n","        patch1 = mpatches.Patch(color = colors[0], label = plot_labels[2])\n","        patch2 = mpatches.Patch(color = colors[1], label = plot_labels[1])\n","        patch3 = mpatches.Patch(color = colors[2], label = plot_labels[0])\n","        plt.legend(handles = [patch1, patch2, patch3])\n","        plt.show()\n","\n","    return freqDomainFeats\n","        \n","            \n","    \n","    \n","    \n","    \n","          \n","\n","    \n","    \n","    \n"]}]},{"cell_type":"code","source":["import numpy as np\n","from scipy.stats import chi2\n","\n","def calculate_rr_noise(rr_intervals, config=None):\n","    \"\"\"\n","    (1) RR ê¸°ë°˜ 4ê°€ì§€ ë…¸ì´ì¦ˆ ê¸°ë²• (3Ïƒ, íˆìŠ¤í† ê·¸ë¨, PoincarÃ©, ë³€ë™ ë²”ìœ„)ì„ ì‚¬ìš©í•´\n","        'RR êµ¬ê°„ì˜ ë…¸ì´ì¦ˆ ë¹„ìœ¨(rr_noise_ratio)'ì„ ê³„ì‚°í•˜ê³ , ì´ë¥¼ ê°€ì¤‘ í‰ê· í•˜ì—¬ ë°˜í™˜.\n","\n","    ë°˜í™˜:\n","      rr_noise_ratio (float): 0~1 ë²”ìœ„ (RR ê¸°ë°˜ ë…¸ì´ì¦ˆ ì •ë„)\n","      detail_dict_rr (dict) : ê° ê¸°ë²•ë³„ ë…¸ì´ì¦ˆ ì •ë³´\n","    \"\"\"\n","    if config is None:\n","        config = {}\n","\n","    sigma_factor        = config.get('sigma_factor', 3.0)         # 3Ïƒ ë°°ìˆ˜\n","    hist_threshold      = config.get('hist_threshold', 0.15)      # ìµœë¹ˆê°’ ëŒ€ë¹„ ì˜¤ì°¨ ë¹„ìœ¨\n","    ellipse_confidence  = config.get('ellipse_confidence', 0.90)  # PoincarÃ© ì‹ ë¢°êµ¬ê°„(ê¸°ë³¸ 90%)\n","    var_range_threshold = config.get('var_range_threshold', 2.0)  # ë³€ë™ ë²”ìœ„ ì„ê³„ê°’\n","    weights             = config.get('weights', [2.0, 3.0, 1.0, 0.5])\n","    # â†‘ [w_sigma, w_hist, w_ellipse, w_varrange]\n","\n","    # RRì´ ë„ˆë¬´ ì ìœ¼ë©´ => ë…¸ì´ì¦ˆ 100% ì²˜ë¦¬\n","    if len(rr_intervals) < 2:\n","        detail_dict_rr = {\n","            'sigma_noise_ratio': 1.0,\n","            'hist_noise_ratio': 1.0,\n","            'ellipse_noise_ratio': 1.0,\n","            'varrange_noise_ratio': 1.0\n","        }\n","        return 1.0, detail_dict_rr\n","\n","    # RR í†µê³„ê°’\n","    mean_rr = np.mean(rr_intervals)\n","    std_rr  = np.std(rr_intervals)\n","\n","    # ---------------------------\n","    # (1) 3Ïƒ ê¸°ë°˜\n","    # ---------------------------\n","    upper_bound = mean_rr + sigma_factor * std_rr\n","    lower_bound = mean_rr - sigma_factor * std_rr\n","    sigma_outliers = np.sum((rr_intervals < lower_bound) | (rr_intervals > upper_bound))\n","    sigma_noise_ratio = sigma_outliers / len(rr_intervals)\n","\n","    # ---------------------------\n","    # (2) íˆìŠ¤í† ê·¸ë¨(ìµœë¹ˆê°’) ê¸°ë°˜\n","    # ---------------------------\n","    bins = np.arange(np.min(rr_intervals), np.max(rr_intervals) + 0.05, 0.05)\n","    hist, bin_edges = np.histogram(rr_intervals, bins=bins)\n","    max_bin_index = np.argmax(hist)\n","    mode_value = (bin_edges[max_bin_index] + bin_edges[max_bin_index+1]) / 2.0\n","    deviations = np.abs(rr_intervals - mode_value)\n","    noise_count_hist = np.sum(deviations > hist_threshold * mode_value)\n","    hist_noise_ratio = noise_count_hist / len(rr_intervals)\n","\n","    # ---------------------------\n","    # (3) PoincarÃ©(íƒ€ì›í˜• ë¶„í¬) ê¸°ë°˜\n","    # ---------------------------\n","    ellipse_threshold = chi2.ppf(ellipse_confidence, df=2)\n","    x = rr_intervals[:-1]\n","    y = rr_intervals[1:]\n","    points = np.column_stack((x, y))\n","    mean_point = np.mean(points, axis=0)\n","    cov_matrix = np.cov(points, rowvar=False)\n","    try:\n","        inv_cov = np.linalg.inv(cov_matrix)\n","        diff_ = points - mean_point\n","        m_distances = np.sqrt(np.sum(diff_ @ inv_cov * diff_, axis=1))\n","        noise_count_ellipse = np.sum(m_distances > ellipse_threshold)\n","        ellipse_noise_ratio = noise_count_ellipse / len(m_distances)\n","    except np.linalg.LinAlgError:\n","        ellipse_noise_ratio = 0.0\n","\n","    # ---------------------------\n","    # (4) ë³€ë™ ë²”ìœ„(MxDMn) ê¸°ë°˜\n","    # ---------------------------\n","    rr_min = np.min(rr_intervals)\n","    rr_max = np.max(rr_intervals)\n","    var_range = rr_max - rr_min\n","    if var_range > var_range_threshold:\n","        varrange_noise_ratio = min(1.0, (var_range - var_range_threshold) / var_range)\n","    else:\n","        varrange_noise_ratio = 0.0\n","\n","    # ---------------------------\n","    # (5) 4ê°€ì§€ ê¸°ë²• ê°€ì¤‘ í‰ê· \n","    # ---------------------------\n","    weighted_sum = (weights[0]*sigma_noise_ratio +\n","                    weights[1]*hist_noise_ratio +\n","                    weights[2]*ellipse_noise_ratio +\n","                    weights[3]*varrange_noise_ratio)\n","    weight_total = sum(weights)\n","    rr_noise_ratio = weighted_sum / weight_total\n","\n","    detail_dict_rr = {\n","        'sigma_noise_ratio': sigma_noise_ratio,\n","        'hist_noise_ratio': hist_noise_ratio,\n","        'ellipse_noise_ratio': ellipse_noise_ratio,\n","        'varrange_noise_ratio': varrange_noise_ratio\n","    }\n","    return rr_noise_ratio, detail_dict_rr"],"metadata":{"id":"QGUrQN1_Rwyb","executionInfo":{"status":"ok","timestamp":1759447226295,"user_tz":-540,"elapsed":698,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from scipy.stats import chi2\n","\n","def calculate_amp_peak_noise(ppg_signal, peak_count, config=None):\n","    \"\"\"\n","    (2) ì§„í­(amplitude) ê¸°ë°˜ + í”¼í¬(peak) ê°œìˆ˜ ê¸°ë°˜ ë…¸ì´ì¦ˆ íŒë³„\n","        - (5) ì§„í­ ê¸°ë°˜:\n","            ppg_signal í‘œì¤€í¸ì°¨ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜(amp_threshold_low ë¯¸ë§Œ)\n","            ë„ˆë¬´ í¬ë©´(amp_threshold_high ì´ˆê³¼) => ë…¸ì´ì¦ˆ=1\n","        - (6) í”¼í¬ ê°œìˆ˜ ê¸°ë°˜:\n","            peak_count < min_peak_count or > max_peak_count => ë…¸ì´ì¦ˆ=1\n","\n","    ë°˜í™˜:\n","      amplitude_noise_flag (int): 0 or 1\n","      peakcount_noise_flag (int): 0 or 1\n","      detail_dict_amppeak (dict)\n","    \"\"\"\n","    if config is None:\n","        config = {}\n","\n","    amp_threshold_low  = config.get('amplitude_threshold_low', 100)\n","    amp_threshold_high = config.get('amplitude_threshold_high', 200000)\n","    min_peak_count     = config.get('min_peak_count', 5)\n","    max_peak_count     = config.get('max_peak_count', 200)\n","\n","    amplitude_noise_flag = 0\n","    peakcount_noise_flag = 0\n","\n","    # (5) ì§„í­ ê¸°ë°˜ => í‘œì¤€í¸ì°¨ê°€ ë²”ìœ„ ë°–ì´ë©´ ë…¸ì´ì¦ˆ=1\n","    if ppg_signal is not None and len(ppg_signal) > 0:\n","        amp_std = np.std(ppg_signal)\n","        if amp_std < amp_threshold_low or amp_std > amp_threshold_high:\n","            amplitude_noise_flag = 1\n","\n","    # (6) í”¼í¬ ê°œìˆ˜ ê¸°ë°˜ => ë²”ìœ„ ë°–ì´ë©´ ë…¸ì´ì¦ˆ=1\n","    if peak_count is not None:\n","        if (peak_count < min_peak_count) or (peak_count > max_peak_count):\n","            peakcount_noise_flag = 1\n","\n","    detail_dict_amppeak = {\n","        'amplitude_noise_flag': amplitude_noise_flag,\n","        'peakcount_noise_flag': peakcount_noise_flag\n","    }\n","    return amplitude_noise_flag, peakcount_noise_flag, detail_dict_amppeak"],"metadata":{"id":"qly9tSPUNReC","executionInfo":{"status":"ok","timestamp":1759447226307,"user_tz":-540,"elapsed":11,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from scipy.stats import chi2\n","\n","def calculate_ppg_var_diff_noise(ppg_signal, config=None):\n","    \"\"\"\n","    (3) PPG ë™ì (ì ì‘í˜•) ì„ê³„ê°’ + ë¯¸ë¶„ ê¸°ë°˜ ë…¸ì´ì¦ˆ ê³„ì‚° (ìœˆë„ìš° ì—†ì´ ì „ì²´ ìƒ˜í”Œ ë‹¨ìœ„)\n","\n","    - ë™ì  ì„ê³„ê°’:\n","      êµ¬ê°„ ì „ì²´ PPG ì‹ í˜¸ì˜ ì „ì—­ í†µê³„ë¥¼ êµ¬í•œ ë’¤, factor ë°°ë§Œí¼ì„ ì„ê³„ê°’ìœ¼ë¡œ ì‚¬ìš©.\n","      ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ” ìƒ˜í”Œë“¤ì˜ ë¹„ìœ¨ì„ 0~1ë¡œ ì‚°ì¶œ.\n","\n","    - ë¯¸ë¶„ ê¸°ë°˜:\n","      ì „ êµ¬ê°„ ë¯¸ë¶„ ì‹ í˜¸ì˜ í‘œì¤€í¸ì°¨(ë˜ëŠ” í‰ê·  ë“±)ì— factorë¥¼ ê³±í•´ ì„ê³„ê°’ ì„¤ì •.\n","      ì´ˆê³¼ ìƒ˜í”Œ ë¹„ìœ¨ì„ 0~1ë¡œ ì‚°ì¶œ.\n","\n","    ë°˜í™˜:\n","      ppg_noise_ratio (float): 0~1 (ë¶„ì‚°+ë¯¸ë¶„ ì¢…í•© ë…¸ì´ì¦ˆ ì •ë„)\n","      detail_dict_ppg (dict) : ì„¸ë¶€ ì •ë³´\n","    \"\"\"\n","    if config is None:\n","        config = {}\n","\n","    # -------------------------------\n","    # (A) íŒŒë¼ë¯¸í„° ë¡œë“œ\n","    # -------------------------------\n","    use_variance_noise   = config.get('use_variance_noise', True)\n","    dynamic_factor       = config.get('dynamic_factor', 1.5)   # ì „ì—­ í†µê³„ ëŒ€ë¹„ ë°°ìˆ˜\n","    use_derivative_noise = config.get('use_derivative_noise', True)\n","    dynamic_diff_factor  = config.get('dynamic_diff_factor', 1.5)\n","\n","    # ìµœì¢… ê°€ì¤‘ì¹˜ (ë¶„ì‚° vs ë¯¸ë¶„)\n","    var_diff_weights = config.get('var_diff_weights', [1.0, 5.0])\n","    var_weight, diff_weight = var_diff_weights[0], var_diff_weights[1]\n","\n","    # -------------------------------\n","    # (B) ì „ì—­ í†µê³„ ê³„ì‚°\n","    # -------------------------------\n","    if ppg_signal is not None and len(ppg_signal) > 0:\n","        global_mean = np.mean(ppg_signal)\n","        global_std  = np.std(ppg_signal)\n","        global_max  = np.max(ppg_signal)\n","        n_samples   = len(ppg_signal)\n","    else:\n","        global_mean = 0.0\n","        global_std  = 0.0\n","        global_max  = 0.0\n","        n_samples   = 0\n","\n","    # ë¯¸ë¶„ ì‹ í˜¸ ì „ì—­ í†µê³„\n","    diff_signal = None\n","    if ppg_signal is not None and len(ppg_signal) > 1:\n","        diff_signal = np.diff(ppg_signal)\n","        global_diff_std = np.std(diff_signal)\n","        n_diff_samples  = len(diff_signal)\n","    else:\n","        global_diff_std = 0.0\n","        n_diff_samples  = 0\n","\n","    # -------------------------------\n","    # (C) ë¶„ì‚°(ë™ì ) ê¸°ë°˜ (ì „ì²´ ìƒ˜í”Œ ë‹¨ìœ„)\n","    # -------------------------------\n","    variance_noise_ratio = 0.0\n","    if use_variance_noise and n_samples > 0:\n","        # ì „ì—­ í‰ê· , í‘œì¤€í¸ì°¨ ê³„ì‚°\n","        lower_bound = global_mean - dynamic_factor * global_std\n","        upper_bound = global_mean + dynamic_factor * global_std\n","\n","        # ë²”ìœ„ ë°– ìƒ˜í”Œ ê°œìˆ˜\n","        exceed_count = np.sum((ppg_signal < lower_bound) | (ppg_signal > upper_bound))\n","\n","        # ì „ì²´ ìƒ˜í”Œ ëŒ€ë¹„ ë¹„ìœ¨\n","        variance_noise_ratio = exceed_count / n_samples\n","\n","    # -------------------------------\n","    # (D) ë¯¸ë¶„(ë™ì ) ê¸°ë°˜ (ì „ì²´ ìƒ˜í”Œ ë‹¨ìœ„)\n","    # -------------------------------\n","    derivative_noise_ratio = 0.0\n","    if use_derivative_noise and diff_signal is not None and n_diff_samples > 0:\n","        # ì „ì—­ ë¯¸ë¶„ ì‹ í˜¸ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨\n","        global_diff_mean = np.mean(diff_signal)\n","        # í‘œì¤€í¸ì°¨ * ë°°ìˆ˜ => ì„ê³„ê°’\n","        dynamic_diff_threshold = global_diff_std * dynamic_diff_factor\n","\n","        # \"í‰ê·  Â± ì„ê³„ê°’\" ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ìƒ˜í”Œ ìˆ˜\n","        exceed_diff_count = np.sum(\n","            np.abs(diff_signal - global_diff_mean) > dynamic_diff_threshold\n","        )\n","\n","        # ì „ì²´ ë¯¸ë¶„ ìƒ˜í”Œ ëŒ€ë¹„ ë¹„ìœ¨\n","        derivative_noise_ratio = exceed_diff_count / n_diff_samples\n","\n","    # -------------------------------\n","    # (E) ìµœì¢… ppg_noise_ratio (ê°€ì¤‘ í‰ê· )\n","    # -------------------------------\n","    total_weight = var_weight + diff_weight\n","    if total_weight > 0:\n","        ppg_noise_ratio = (\n","            var_weight * variance_noise_ratio +\n","            diff_weight * derivative_noise_ratio\n","        ) / total_weight\n","    else:\n","        ppg_noise_ratio = 0.0\n","\n","    # -------------------------------\n","    # (F) detail_dict_ppg\n","    # -------------------------------\n","    detail_dict_ppg = {\n","        'variance_noise_ratio': variance_noise_ratio,\n","        'derivative_noise_ratio': derivative_noise_ratio,\n","        'ppg_noise_ratio': ppg_noise_ratio,\n","\n","        # # ì „ì—­ í†µê³„ ë¡œê·¸ìš©\n","        # 'global_mean': global_mean,\n","        # 'global_std':  global_std,\n","        # 'global_max':  global_max,\n","        # 'global_diff_std': global_diff_std\n","    }\n","\n","    return ppg_noise_ratio, detail_dict_ppg"],"metadata":{"id":"lDv2GZ9gR3yK","executionInfo":{"status":"ok","timestamp":1759447226693,"user_tz":-540,"elapsed":16,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def calculate_noise(rr_intervals, ppg_signal=None, peak_count=None, config=None):\n","    \"\"\"\n","    (4) ìµœì¢… ë…¸ì´ì¦ˆ ê³„ì‚° í•¨ìˆ˜\n","        1) RR ê¸°ë°˜ ë…¸ì´ì¦ˆ(rr_noise_ratio)\n","        2) ì§„í­/í”¼í¬ ë…¸ì´ì¦ˆ(ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ 1ì´ë©´ -> ì¦‰ì‹œ ë…¸ì´ì¦ˆ)\n","        3) PPG ë¶„ì‚°/ë¯¸ë¶„ ë…¸ì´ì¦ˆ(ppg_noise_ratio)\n","\n","        - RR vs PPGë„ ê°€ì¤‘ í‰ê· í•˜ì—¬ combined_noise_ratio\n","        - amplitude_noise_flag or peakcount_noise_flagê°€ 1ì´ë©´ max()ë¡œ ìµœì¢… 1\n","    \"\"\"\n","    if config is None:\n","        config = {}\n","\n","    # -----------------------\n","    # (A) RR ê¸°ë°˜ ë…¸ì´ì¦ˆ\n","    # -----------------------\n","    rr_noise_ratio, detail_rr = calculate_rr_noise(rr_intervals, config=config)\n","\n","    # -----------------------\n","    # (B) ì§„í­/í”¼í¬ ë…¸ì´ì¦ˆ í”Œë˜ê·¸\n","    # -----------------------\n","    amplitude_noise_flag, peakcount_noise_flag, detail_amppeak = \\\n","        calculate_amp_peak_noise(ppg_signal, peak_count, config=config)\n","\n","    # -----------------------\n","    # (C) PPG ë¶„ì‚°/ë¯¸ë¶„ ê¸°ë°˜\n","    # -----------------------\n","    ppg_noise_ratio, detail_ppg = calculate_ppg_var_diff_noise(ppg_signal, config=config)\n","    variance_noise_ratio   = detail_ppg['variance_noise_ratio']\n","    derivative_noise_ratio = detail_ppg['derivative_noise_ratio']\n","\n","    # -----------------------\n","    # (D) RR vs PPG ê°€ì¤‘ì¹˜\n","    # -----------------------\n","    rr_weight  = config.get('rr_weight', 1.0)\n","    ppg_weight = config.get('ppg_weight', 1.0)\n","\n","    if (rr_weight + ppg_weight) > 0:\n","        combined_noise_ratio = (\n","            rr_weight * rr_noise_ratio +\n","            ppg_weight * ppg_noise_ratio\n","        ) / (rr_weight + ppg_weight)\n","    else:\n","        combined_noise_ratio = rr_noise_ratio\n","\n","    # -----------------------\n","    # (F) ìµœì¢… ë…¸ì´ì¦ˆ ê²°ì •\n","    # -----------------------\n","    #   - amplitude_noise_flag=1 or peakcount_noise_flag=1 ì´ë©´ => max=1\n","    final_noise_ratio = max(\n","        combined_noise_ratio,\n","        amplitude_noise_flag,\n","        peakcount_noise_flag\n","    )\n","\n","    # -----------------------\n","    # (G) detail_dict í•©ì¹˜ê¸°\n","    # -----------------------\n","    detail_dict = {}\n","    detail_dict.update(detail_rr)       # RR ê¸°ë°˜\n","    detail_dict.update(detail_amppeak)  # ì§„í­/í”¼í¬\n","    detail_dict.update(detail_ppg)      # PPG ë¶„ì‚°/ë¯¸ë¶„\n","\n","    # ì£¼ìš” ê°’ ê¸°ë¡\n","    detail_dict['rr_noise_ratio']       = rr_noise_ratio\n","    detail_dict['variance_noise_ratio'] = variance_noise_ratio\n","    detail_dict['derivative_noise_ratio'] = derivative_noise_ratio\n","    detail_dict['ppg_noise_ratio']      = ppg_noise_ratio\n","    detail_dict['combined_noise_ratio'] = combined_noise_ratio\n","    detail_dict['amplitude_noise_flag'] = amplitude_noise_flag\n","    detail_dict['peakcount_noise_flag'] = peakcount_noise_flag\n","    detail_dict['final_noise_ratio']    = final_noise_ratio\n","\n","    return final_noise_ratio, detail_dict\n","\n","\n","def calculate_SQI(rr_intervals, ppg_signal=None, peak_count=None, config=None):\n","    \"\"\"\n","    (5) SQI = 1 - final_noise_ratio\n","    \"\"\"\n","    final_noise_ratio, detail_dict = calculate_noise(\n","        rr_intervals=rr_intervals,\n","        ppg_signal=ppg_signal,\n","        peak_count=peak_count,\n","        config=config\n","    )\n","    sqi = 1 - final_noise_ratio\n","    return sqi, final_noise_ratio, detail_dict"],"metadata":{"id":"SUC8ik80SEaf","executionInfo":{"status":"ok","timestamp":1759447227260,"user_tz":-540,"elapsed":11,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import sys\n","import os\n","\n","# íŒŒì¼ ê²½ë¡œ\n","data_path = \"/content/drive/MyDrive/ê°€ì²œëŒ€/RA/[wearable] ê³¼ì œ/HRV ë¶„ì„/ppg_total_sorted_j70Iq7TuEUhAH1y9QTyiXawI97N2.csv\"\n","\n","# ì €ì¥ ê²½ë¡œ (ì›ë³¸ ë®ì–´ì“°ê¸° or ìƒˆ íŒŒì¼ ì €ì¥)\n","save_as_new_file = True  # Trueë©´ ìƒˆ íŒŒì¼ë¡œ ì €ì¥, Falseë©´ ì›ë³¸ ë®ì–´ì“°ê¸°\n","\n","# ë°ì´í„° ë¡œë”©\n","try:\n","    df = pd.read_csv(data_path)\n","    print(f\"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {df.shape}\")\n","except Exception as e:\n","    print(f\"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}\")\n","    sys.exit(1)\n","\n","# ì—´ ì´ë¦„ í†µì¼\n","df = df.rename(columns={'timestamp': 'time', 'ppg_raw': 'value'})\n","\n","# 1. ì¤‘ë³µ íšŸìˆ˜ ì„¸ê¸°\n","time_counts = df['time'].value_counts()\n","duplicated_times = time_counts[time_counts > 1]\n","print(f\"\\nğŸ” ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: {len(duplicated_times)}\")\n","\n","# 2. ì¤‘ë³µ íšŸìˆ˜ ë¶„í¬\n","dup_distribution = duplicated_times.value_counts().sort_index()\n","print(\"\\nğŸ“Š ì¤‘ë³µ íšŸìˆ˜ ë¶„í¬:\")\n","for count, n_times in dup_distribution.items():\n","    print(f\"  {count}ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: {n_times}\")\n","\n","# 3. ì¤‘ë³µ ì œê±° (keep='first' ë˜ëŠ” 'last' ì„ íƒ ê°€ëŠ¥)\n","before = len(df)\n","df_cleaned = df.drop_duplicates(subset='time', keep='first').reset_index(drop=True)\n","after = len(df_cleaned)\n","print(f\"\\nğŸ§¹ ì¤‘ë³µ ì œê±° ì™„ë£Œ: {before - after}ê°œ ì œê±°ë¨ (ì´ {after}ê°œ ë‚¨ìŒ)\")\n","\n","# 4. ì €ì¥\n","if save_as_new_file:\n","    folder = os.path.dirname(data_path)\n","    filename = os.path.basename(data_path)\n","    name, ext = os.path.splitext(filename)\n","    new_filename = f\"{name}_deduplicated{ext}\"\n","    new_path = os.path.join(folder, new_filename)\n","else:\n","    new_path = data_path  # ì›ë³¸ ë®ì–´ì“°ê¸°\n","\n","try:\n","    df_cleaned.to_csv(new_path, index=False)\n","    print(f\"\\nğŸ’¾ ì¤‘ë³µ ì œê±°ëœ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {new_path}\")\n","except Exception as e:\n","    print(f\"âŒ ì €ì¥ ì˜¤ë¥˜: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gytWf5vQWJt_","executionInfo":{"status":"ok","timestamp":1759447411909,"user_tz":-540,"elapsed":184154,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}},"outputId":"6e951647-85af-4edd-aa0e-fe896e355d9c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: (76553840, 5)\n","\n","ğŸ” ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 3482097\n","\n","ğŸ“Š ì¤‘ë³µ íšŸìˆ˜ ë¶„í¬:\n","  2ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 489731\n","  3ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 134852\n","  4ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 4173\n","  5ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 1\n","  7ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 17522\n","  9ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 539114\n","  10ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 334720\n","  12ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 514005\n","  18ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 87001\n","  19ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 39971\n","  22ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 296453\n","  24ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 31500\n","  26ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 130\n","  28ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 1\n","  30ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 259449\n","  31ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 89716\n","  32ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 36623\n","  33ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 64570\n","  34ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 10200\n","  38ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 280\n","  39ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 2100\n","  41ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 157871\n","  42ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 48329\n","  44ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 1\n","  46ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 1544\n","  51ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 30172\n","  59ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 6787\n","  61ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 1\n","  63ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 300\n","  64ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 2426\n","  73ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 95453\n","  74ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 13347\n","  77ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 3990\n","  80ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 2027\n","  102ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 66910\n","  104ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 68167\n","  114ë²ˆ ì¤‘ë³µëœ time ê°’ ê°œìˆ˜: 32660\n","\n","ğŸ§¹ ì¤‘ë³µ ì œê±° ì™„ë£Œ: 73071743ê°œ ì œê±°ë¨ (ì´ 3482097ê°œ ë‚¨ìŒ)\n","\n","ğŸ’¾ ì¤‘ë³µ ì œê±°ëœ íŒŒì¼ ì €ì¥ ì™„ë£Œ: /content/drive/MyDrive/ê°€ì²œëŒ€/RA/[wearable] ê³¼ì œ/HRV ë¶„ì„/ppg_total_sorted_j70Iq7TuEUhAH1y9QTyiXawI97N2_deduplicated.csv\n"]}]},{"cell_type":"code","source":["# ì „ì²˜ë¦¬ ì´í›„\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import random\n","import numpy as np\n","import scipy.signal as signal\n","import sys\n","import warnings\n","\n","sys.path.append('/content/HRV')  # HRV ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€\n","\n","# ë¶ˆí•„ìš”í•œ ê²½ê³  ì œê±°\n","warnings.simplefilter(\"ignore\", UserWarning)\n","\n","# Matplotlib ì„¤ì • (í°íŠ¸ ë¬¸ì œ ë°©ì§€)\n","plt.rcParams['font.family'] = 'sans-serif'\n","plt.rcParams['axes.unicode_minus'] = False\n","\n","# HRV ëª¨ë“ˆ import\n","from timeDomain import timeDomain\n","from frequencyDomain import frequencyDomain\n","# from SQI import calculate_SQI  # SQI í•¨ìˆ˜ë„ í•„ìš” ì‹œ import\n","\n","# --- 1. PPG ë°ì´í„° ë¡œë”© ---\n","# PpgGreen_total.csv ê²½ë¡œ\n","data_path = \"/content/drive/MyDrive/ê°€ì²œëŒ€/RA/[wearable] ê³¼ì œ/HRV ë¶„ì„/Datas/ëª¨ë°”ì¼ ë°ì´í„°/ê°•í˜„ìŠ¹1/total/PpgGreen_total_ê°•í˜„ìŠ¹1[2024-11-28~2024-12-11].csv\"\n","# data_path = \"/content/drive/MyDrive/ê°€ì²œëŒ€/RA/[wearable] ê³¼ì œ/HRV ë¶„ì„/ppg_total_sorted_j70Iq7TuEUhAH1y9QTyiXawI97N2_deduplicated.csv\"\n","\n","try:\n","    df = pd.read_csv(data_path)\n","    print(f\"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {df.shape}\")\n","except Exception as e:\n","    print(f\"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}\")\n","    sys.exit(1)\n","\n","# --- 2. ì—´ ì´ë¦„ í†µì¼ ---\n","# timestamp â†’ time, ppg_raw â†’ value\n","df = df.rename(columns={'timestamp': 'time', 'ppg_raw': 'value'})\n","\n","# --- 3. ì¤‘ë³µ ì‹œê°„ê°’ ì œê±° ---\n","before_drop = len(df)\n","df = df.drop_duplicates(subset='time').reset_index(drop=True)\n","after_drop = len(df)\n","print(f\"ğŸ§¹ ì¤‘ë³µ ì œê±° ì™„ë£Œ: {before_drop - after_drop}ê°œ ì œê±°ë¨ (ì´ {after_drop}ê°œ ë‚¨ìŒ)\")\n","\n","# --- 4. ì‹œê°„ ë³€í™˜ ë° ì •ë ¬ ---\n","try:\n","    df['time'] = pd.to_datetime(df['time'], unit='ms')\n","    df = df.sort_values(by='time').reset_index(drop=True)\n","except Exception as e:\n","    print(f\"âŒ ì‹œê°„ ë³€í™˜ ì˜¤ë¥˜: {e}\")\n","    sys.exit(1)\n","\n","# --- 5. ìœ íš¨í•œ 60ì´ˆ êµ¬ê°„ ì°¾ê¸° ---\n","valid_start_times = df[df['time'] <= df['time'].max() - pd.Timedelta(seconds=60)]['time'].tolist()\n","print(f\"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ 60ì´ˆ êµ¬ê°„ ê°œìˆ˜: {len(valid_start_times)}\")\n","\n","if len(valid_start_times) == 0:\n","    print(\"âš ï¸ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n","    sys.exit(1)\n","\n","# --- 6. ëœë¤ êµ¬ê°„ ì„ íƒ ---\n","random_sections = 50\n","selected_start_times = random.sample(valid_start_times, min(len(valid_start_times), random_sections))\n","\n","# --- 7. ê° êµ¬ê°„ì— ëŒ€í•´ ë¶„ì„ ---\n","def bandpass_filter(data, fs, lowcut=0.5, highcut=4.0, order=2):\n","    nyq = 0.5 * fs\n","    low = lowcut / nyq\n","    high = highcut / nyq\n","    b, a = signal.butter(order, [low, high], btype='band')\n","    return signal.filtfilt(b, a, data)\n","\n","for i, start_time in enumerate(selected_start_times):\n","    end_time = start_time + pd.Timedelta(seconds=60)\n","    filtered_df = df[(df['time'] >= start_time) & (df['time'] < end_time)].copy()\n","    data_count = len(filtered_df)\n","    print(f\"\\nğŸŸ¢ [êµ¬ê°„ {i+1}] {start_time} ~ {end_time}, ë°ì´í„° ê°œìˆ˜: {data_count}\")\n","\n","    if data_count < 500:\n","        print(\"âš ï¸ ë°ì´í„°ê°€ ë¶€ì¡±í•œ êµ¬ê°„ì…ë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n","        continue\n","\n","    # í•„í„°ë§\n","    fs = 25  # Hz\n","    filtered_df['filtered'] = bandpass_filter(filtered_df['value'], fs)\n","\n","    # í”¼í¬ ê²€ì¶œ\n","    min_distance = int(0.33 * fs)\n","    peaks, _ = signal.find_peaks(filtered_df['filtered'], distance=min_distance)\n","    if len(peaks) < 5:\n","        print(\"âš ï¸ í”¼í¬ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n","        continue\n","    print(f\"âœ… ê²€ì¶œëœ í”¼í¬ ê°œìˆ˜: {len(peaks)}\")\n","\n","    # RR interval ê³„ì‚°\n","    peak_times = filtered_df['time'].iloc[peaks].values\n","    rr_intervals = np.diff(peak_times) / np.timedelta64(1, 's')\n","    if len(rr_intervals) < 5:\n","        print(\"âš ï¸ RR intervalì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n","        continue\n","    print(f\"âœ… RR intervals ê°œìˆ˜: {len(rr_intervals)}\")\n","\n","    # SQI ê³„ì‚°\n","    try:\n","        sqi, noise_ratio, detail_dict = calculate_SQI(rr_intervals=rr_intervals,\n","                                                      ppg_signal=filtered_df['filtered'],\n","                                                      peak_count=len(peaks))\n","        print(f\"âœ… ë…¸ì´ì¦ˆ ë¹„ìœ¨: {noise_ratio:.2f}, SQI: {sqi:.2f}\")\n","        print(\"\\nğŸ” Detail Dict:\")\n","        for key, val in detail_dict.items():\n","            print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {key}: {val}\")\n","    except Exception as e:\n","        print(f\"âŒ SQI ê³„ì‚° ì˜¤ë¥˜: {e}\")\n","        continue\n","\n","    # HRV ë¶„ì„\n","    try:\n","        time_feats = timeDomain(rr_intervals)\n","        freq_feats = frequencyDomain(rr_intervals)\n","    except Exception as e:\n","        print(f\"âŒ HRV ë¶„ì„ ì˜¤ë¥˜: {e}\")\n","        continue\n","\n","    # ê·¸ë˜í”„ ì¶œë ¥\n","    plt.figure(figsize=(12, 4))\n","    plt.plot(filtered_df['time'], filtered_df['value'], label='Raw PPG', color='blue')\n","    plt.title(f\"Raw PPG (Interval {i+1})\")\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"PPG Value\")\n","    plt.legend()\n","    plt.show()\n","\n","    plt.figure(figsize=(12, 4))\n","    plt.plot(filtered_df['time'], filtered_df['filtered'], label='Filtered PPG', color='green')\n","    plt.scatter(filtered_df['time'].iloc[peaks], filtered_df['filtered'].iloc[peaks], color='red', label='Detected Peaks')\n","    plt.title(f\"Filtered PPG with Peaks (Interval {i+1})\")\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"PPG Value\")\n","    plt.legend()\n","    plt.show()\n","\n","    # ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ê·¸ë˜í”„\n","    try:\n","        freq_feats_plot = frequencyDomain(rr_intervals, plot=1)\n","    except Exception as e:\n","        print(f\"âŒ ì£¼íŒŒìˆ˜ ì˜ì—­ HRV ê·¸ë˜í”„ ì˜¤ë¥˜: {e}\")\n","\n","    # ê²°ê³¼ ì¶œë ¥\n","    print(\"\\nâœ… Time Domain HRV Features:\")\n","    for k, v in time_feats.items():\n","        print(f\"{k}: {v}\")\n","\n","    print(\"\\nâœ… Frequency Domain HRV Features:\")\n","    for k, v in freq_feats.items():\n","        print(f\"{k}: {v}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"17qB2yg9IvLF2q_rDaZzFBdLP5z52AWTZ"},"id":"bF2t5dgG_Ze7","executionInfo":{"status":"ok","timestamp":1759447494990,"user_tz":-540,"elapsed":83076,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}},"outputId":"087d5349-41c9-4255-97ed-0a31ac749162"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import random\n","import numpy as np\n","import scipy.signal as signal\n","import sys\n","import warnings\n","\n","sys.path.append('/content/HRV')  # HRV ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€\n","\n","# ë¶ˆí•„ìš”í•œ ê²½ê³  ì œê±°\n","warnings.simplefilter(\"ignore\", UserWarning)\n","\n","# Matplotlib ì„¤ì • (í°íŠ¸ ë¬¸ì œ ë°©ì§€)\n","plt.rcParams['font.family'] = 'sans-serif'\n","plt.rcParams['axes.unicode_minus'] = False\n","\n","# HRV ëª¨ë“ˆ import\n","from timeDomain import timeDomain\n","from frequencyDomain import frequencyDomain\n","\n","# --- 1. PPG ë°ì´í„° ë¡œë”© ---\n","sensor_data = {}\n","\n","# PpgGreen ì„¼ì„œë§Œ ì‚¬ìš©\n","sensor_configs = {'PpgGreen': ['time', 'value']}\n","\n","# ë°ì´í„° ê²½ë¡œ (Colab ê²½ë¡œ)\n","data_path = \"/content/drive/MyDrive/á„€á…¡á„á…¥á†«á„ƒá…¢/RA/[wearable] á„€á…ªá„Œá…¦/HRV á„‡á…®á†«á„‰á…¥á†¨/Datas/á„†á…©á„‡á…¡á„‹á…µá†¯ á„ƒá…¦á„‹á…µá„á…¥/á„€á…¡á†¼á„’á…§á†«á„‰á…³á†¼/total/PpgGreen_total.csv\"\n","\n","try:\n","    # íŒŒì¼ ì½ê¸° ë° ë°ì´í„° ì €ì¥\n","    for sensor, columns in sensor_configs.items():\n","        sensor_files = [f for f in os.listdir(data_path) if f.startswith(sensor)]\n","        data_frames = []\n","\n","        for file in sensor_files:\n","            file_path = os.path.join(data_path, file)\n","            try:\n","                df = pd.read_csv(file_path, names=columns, header=0)\n","                data_frames.append(df)\n","            except Exception as e:\n","                print(f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file} - {e}\")\n","\n","        if data_frames:\n","            sensor_data[sensor] = pd.concat(data_frames, ignore_index=True)\n","\n","except Exception as e:\n","    print(f\"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}\")\n","    sys.exit(1)\n","\n","# --- 2. PPG ë°ì´í„° ì²˜ë¦¬ ---\n","if 'PpgGreen' in sensor_data:\n","    df = sensor_data['PpgGreen']\n","\n","    # âœ… ë°ì´í„° í¬ê¸° í™•ì¸\n","    print(f\"âœ… ë¡œë“œëœ PpgGreen ë°ì´í„° í¬ê¸°: {df.shape}\")\n","\n","    try:\n","        # ì‹œê°„ ë°ì´í„° ë³€í™˜ ë° ì •ë ¬\n","        df['time'] = pd.to_datetime(df['time'], unit='ms')\n","        df = df.sort_values(by='time').reset_index(drop=True)\n","    except Exception as e:\n","        print(f\"âŒ ì‹œê°„ ë³€í™˜ ì˜¤ë¥˜: {e}\")\n","        sys.exit(1)\n","\n","    # âœ… ìœ íš¨í•œ 60ì´ˆ êµ¬ê°„ ì°¾ê¸°\n","    valid_start_times = df[df['time'] <= df['time'].max() - pd.Timedelta(seconds=60)]['time'].tolist()\n","\n","    # âœ… ì‚¬ìš© ê°€ëŠ¥í•œ 60ì´ˆ êµ¬ê°„ ê°œìˆ˜ í™•ì¸\n","    print(f\"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ 60ì´ˆ êµ¬ê°„ ê°œìˆ˜: {len(valid_start_times)}\")\n","\n","    if len(valid_start_times) == 0:\n","        print(\"âš ï¸ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n","        sys.exit(1)\n","\n","    # âœ… Nê°œì˜ ëœë¤ êµ¬ê°„ ì„ íƒ\n","    random_sections = 50\n","    selected_start_times = random.sample(valid_start_times, random_sections)\n","\n","    # --- 3. Nê°œ êµ¬ê°„ì— ëŒ€í•´ ë¶„ì„ ---\n","    for i, random_start_time in enumerate(selected_start_times):\n","        end_time = random_start_time + pd.Timedelta(seconds=60)\n","        filtered_df = df[(df['time'] >= random_start_time) & (df['time'] < end_time)].copy()\n","\n","        # âœ… êµ¬ê°„ë³„ ë°ì´í„° ê°œìˆ˜ í™•ì¸\n","        data_count = len(filtered_df)\n","        print(f\"\\nğŸŸ¢ [êµ¬ê°„ {i+1}] {random_start_time} ~ {end_time}, ë°ì´í„° ê°œìˆ˜: {data_count}\")\n","\n","        if data_count < 500:\n","            print(\"âš ï¸ ë°ì´í„°ê°€ ë¶€ì¡±í•œ êµ¬ê°„ì…ë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n","            continue\n","\n","        # --- 4. í•„í„°ë§ ---\n","        def bandpass_filter(data, fs, lowcut=0.5, highcut=4.0, order=2):\n","            nyq = 0.5 * fs\n","            low = lowcut / nyq\n","            high = highcut / nyq\n","            b, a = signal.butter(order, [low, high], btype='band')\n","            return signal.filtfilt(b, a, data)\n","\n","        fs = 25  # ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ (Hz)\n","        filtered_df['filtered'] = bandpass_filter(filtered_df['value'], fs)\n","\n","        # --- 5. í”¼í¬ ê²€ì¶œ ---\n","        min_distance = int(0.33 * fs)   // ì•½ 180bpm\n","        peaks, _ = signal.find_peaks(filtered_df['filtered'], distance=min_distance)\n","        peak_count = len(peaks)\n","\n","        # âœ… í”¼í¬ ê°œìˆ˜ í™•ì¸\n","        print(f\"âœ… ê²€ì¶œëœ í”¼í¬ ê°œìˆ˜: {len(peaks)}\")\n","\n","        if len(peaks) < 5:\n","            print(\"âš ï¸ í”¼í¬ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n","            continue\n","\n","        # --- 6. RR interval ê³„ì‚° ---\n","        peak_times = filtered_df['time'].iloc[peaks].values\n","        rr_intervals = np.diff(peak_times) / np.timedelta64(1, 's')\n","\n","        # âœ… RR interval ê°œìˆ˜ í™•ì¸\n","        print(f\"âœ… RR intervals ê°œìˆ˜: {len(rr_intervals)}\")\n","\n","        if len(rr_intervals) < 5:\n","            print(\"âš ï¸ RR intervalì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n","            continue\n","\n","        # --- 7. ë…¸ì´ì¦ˆ ë° SQI ê³„ì‚° ---\n","        sqi, noise_ratio, detail_dict = calculate_SQI(rr_intervals=rr_intervals,\n","                                                 ppg_signal=filtered_df['filtered'],\n","                                                 peak_count=peak_count)\n","        print(f\"âœ… ë…¸ì´ì¦ˆ ë¹„ìœ¨: {noise_ratio:.2f}, SQI: {sqi:.2f}\")\n","\n","        # detail_dict ê¹”ë”í•˜ê²Œ ì¶œë ¥\n","        print(\"\\nğŸ” Detail Dict:\")\n","        for key, val in detail_dict.items():\n","            # ê°’ì´ floatì¸ ê²½ìš° ì†Œìˆ˜ì  2ìë¦¬, intì¸ ê²½ìš° ê·¸ëƒ¥ ì¶œë ¥\n","            if isinstance(val, float):\n","                print(f\"  {key}: {val:.4f}\")\n","            else:\n","                print(f\"  {key}: {val}\")\n","\n","        # --- 8. HRV ë¶„ì„ ---\n","        try:\n","            timeDomainFeats = timeDomain(rr_intervals)\n","            freqDomainFeats = frequencyDomain(rr_intervals)\n","        except Exception as e:\n","            print(f\"âŒ HRV ë¶„ì„ ì˜¤ë¥˜: {e}\")\n","            continue\n","\n","        # --- 9. ê·¸ë˜í”„ ì¶œë ¥ ---\n","        plt.figure(figsize=(12, 4))\n","        plt.plot(filtered_df['time'], filtered_df['value'], label='Raw PpgGreen', color='blue')\n","        plt.title(f\"Raw PpgGreen Signal (Interval {i+1}: {random_start_time})\")\n","        plt.xlabel(\"Time\")\n","        plt.ylabel(\"PPG Value\")\n","        plt.legend()\n","        plt.show()\n","\n","        plt.figure(figsize=(12, 4))\n","        plt.plot(filtered_df['time'], filtered_df['filtered'], label='Filtered PpgGreen', color='green')\n","        plt.scatter(filtered_df['time'].iloc[peaks], filtered_df['filtered'].iloc[peaks], color='red', label='Detected Peaks')\n","        plt.title(f\"Filtered PpgGreen with Detected Peaks (Interval {i+1}: {random_start_time})\")\n","        plt.xlabel(\"Time\")\n","        plt.ylabel(\"PPG Value\")\n","        plt.legend()\n","        plt.show()\n","\n","        # --- 10. HRV ë¶„ì„ (ì‹œê°„ & ì£¼íŒŒìˆ˜ ë„ë©”ì¸) ---\n","        try:\n","            timeDomainFeats = timeDomain(rr_intervals)\n","            freqDomainFeats = frequencyDomain(rr_intervals, plot=1)  # plot=1 ì¶”ê°€í•´ì„œ ì£¼íŒŒìˆ˜ ê·¸ë˜í”„ ìë™ ì¶œë ¥\n","        except Exception as e:\n","            print(f\"âŒ HRV ë¶„ì„ ì˜¤ë¥˜: {e}\")\n","            continue\n","\n","        # --- 11. HRV ê²°ê³¼ ì¶œë ¥ ---\n","        print(\"\\nâœ… Time Domain HRV Features:\")\n","        for key, value in timeDomainFeats.items():\n","            print(f\"{key}: {value}\")\n","\n","        print(\"\\nâœ… Frequency Domain HRV Features:\")\n","        for key, value in freqDomainFeats.items():\n","            print(f\"{key}: {value}\")\n","\n","else:\n","    print(\"âŒ PpgGreen ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n","    sys.exit(1)"],"metadata":{"id":"0DmbuWvdgUu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import sys\n","\n","# ë¶„ì„í•  í´ë” ê²½ë¡œë“¤\n","folder_paths = [\n","    \"/content/drive/MyDrive/ê°€ì²œëŒ€/RA/[wearable] ê³¼ì œ/HRV ë¶„ì„/Datas/ëª¨ë°”ì¼ ë°ì´í„°/ê°•í˜„ìŠ¹\",\n","    \"/content/drive/MyDrive/ê°€ì²œëŒ€/RA/[wearable] ê³¼ì œ/HRV ë¶„ì„/Datas/ëª¨ë°”ì¼ ë°ì´í„°/ê¹€í˜•ìš±\",\n","    \"/content/drive/MyDrive/ê°€ì²œëŒ€/RA/[wearable] ê³¼ì œ/HRV ë¶„ì„/Datas/ëª¨ë°”ì¼ ë°ì´í„°/ì†¡í˜„\"\n","]\n","\n","def load_ppg_data_from_folder(folder_path, sensor_prefix=\"PpgGreen_\"):\n","    \"\"\"\n","    í´ë” ì•ˆì˜ PpgGreen_*.csv íŒŒì¼ì„ ì „ë¶€ ì½ì–´ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì³ ë°˜í™˜.\n","    (os.listdir + startswith ì‚¬ìš©)\n","    \"\"\"\n","    try:\n","        all_files = os.listdir(folder_path)\n","    except FileNotFoundError:\n","        print(f\"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}\")\n","        return None\n","    except Exception as e:\n","        print(f\"âŒ os.listdir ì˜¤ë¥˜: {folder_path}, {e}\")\n","        return None\n","\n","    # PpgGreen_ë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ë§Œ ê³¨ë¼ì„œ ì½ê¸°\n","    sensor_files = [f for f in all_files if f.startswith(sensor_prefix)]\n","    if not sensor_files:\n","        print(f\"âš ï¸ {folder_path} í´ë”ì— {sensor_prefix} ê´€ë ¨ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n","        return None\n","\n","    df_list = []\n","    for file_name in sensor_files:\n","        file_path = os.path.join(folder_path, file_name)\n","        try:\n","            df = pd.read_csv(file_path, header=0, names=[\"time\", \"value\"])\n","            df_list.append(df)\n","        except Exception as e:\n","            print(f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_name} - {e}\")\n","\n","    if df_list:\n","        combined_df = pd.concat(df_list, ignore_index=True)\n","        return combined_df\n","    else:\n","        return None\n","\n","def analyze_1min_intervals(df):\n","    \"\"\"\n","    DataFrame(df)ì˜ time ì»¬ëŸ¼(ì´ë¯¸ datetime ë³€í™˜ë¨)ì„ ì´ìš©í•´\n","    - ì²˜ìŒë¶€í„° ëê¹Œì§€ 1ë¶„ ë‹¨ìœ„ë¡œ ìª¼ê°°ì„ ë•Œ ëª‡ ê°œ êµ¬ê°„ì´ ë‚˜ì˜¤ëŠ”ì§€ (interval_count)\n","    - ê° êµ¬ê°„ë³„ ë°ì´í„° ê°œìˆ˜ì˜ í‰ê·  (avg_data_count)\n","    ë¥¼ ë°˜í™˜í•œë‹¤.\n","    \"\"\"\n","    df = df.sort_values(by='time').reset_index(drop=True)\n","    start_time = df['time'].iloc[0]\n","    end_time = df['time'].iloc[-1]\n","\n","    one_minute = pd.Timedelta(seconds=60)\n","    intervals_data_counts = []  # ê° êµ¬ê°„ì˜ ë°ì´í„° ê°œìˆ˜ë¥¼ ì €ì¥\n","\n","    current = start_time\n","    while current + one_minute <= end_time:\n","        # í˜„ì¬ êµ¬ê°„ì˜ ë ì‹œê°„\n","        current_end = current + one_minute\n","\n","        # í•´ë‹¹ êµ¬ê°„ì— ì†í•˜ëŠ” ë°ì´í„°ë§Œ ì¶”ì¶œ\n","        mask = (df['time'] >= current) & (df['time'] < current_end)\n","        data_count = mask.sum()  # êµ¬ê°„ ë‚´ ë°ì´í„° ê°œìˆ˜\n","        intervals_data_counts.append(data_count)\n","\n","        current = current_end\n","\n","    interval_count = len(intervals_data_counts)\n","    if interval_count > 0:\n","        avg_data_count = sum(intervals_data_counts) / interval_count\n","    else:\n","        avg_data_count = 0\n","\n","    return interval_count, avg_data_count\n","\n","# ë©”ì¸ ì‹¤í–‰ë¶€\n","if __name__ == \"__main__\":\n","    for idx, folder_path in enumerate(folder_paths, start=1):\n","        folder_name = os.path.basename(folder_path)\n","        ppg_df = load_ppg_data_from_folder(folder_path, sensor_prefix=\"PpgGreen_\")\n","\n","        if ppg_df is None or len(ppg_df) == 0:\n","            print(f\"[Folder {idx}] {folder_name} - PpgGreen ë°ì´í„° ì—†ìŒ ë˜ëŠ” ë¡œë“œ ì‹¤íŒ¨\\n\")\n","            continue\n","\n","        # ì „ì²´ ë°ì´í„° í¬ê¸°\n","        total_data_size = len(ppg_df)\n","\n","        # time ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜\n","        try:\n","            ppg_df['time'] = pd.to_datetime(ppg_df['time'], unit='ms')\n","        except Exception as e:\n","            print(f\"[Folder {idx}] {folder_name} - time ë³€í™˜ ì˜¤ë¥˜: {e}\\n\")\n","            continue\n","\n","        # 1ë¶„ ë‹¨ìœ„ êµ¬ê°„ ìˆ˜ ë° í‰ê·  ë°ì´í„° ê°œìˆ˜ ê³„ì‚°\n","        interval_count, avg_data_count = analyze_1min_intervals(ppg_df)\n","\n","        print(f\"[Folder {idx}] {folder_name}\")\n","        print(f\" - ì „ì²´ ë°ì´í„° í¬ê¸°: {total_data_size}\")\n","        print(f\" - 1ë¶„ êµ¬ê°„ ê°œìˆ˜: {interval_count}\")\n","        print(f\" - ê° êµ¬ê°„ í‰ê·  ë°ì´í„° ê°œìˆ˜: {avg_data_count:.2f}\\n\")\n","\n","    print(\"ëª¨ë“  í´ë” ì²˜ë¦¬ ì™„ë£Œ!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3pWL-ZhbMCI","executionInfo":{"status":"ok","timestamp":1741797926117,"user_tz":-540,"elapsed":13208800,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}},"outputId":"ecf1eb65-5c07-4bcb-cdac-a1a5cfc6a984"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Folder 1] ê°•í˜„ìŠ¹\n"," - ì „ì²´ ë°ì´í„° í¬ê¸°: 9480886\n"," - 1ë¶„ êµ¬ê°„ ê°œìˆ˜: 18739\n"," - ê° êµ¬ê°„ í‰ê·  ë°ì´í„° ê°œìˆ˜: 505.87\n","\n","[Folder 2] ê¹€í˜•ìš±\n"," - ì „ì²´ ë°ì´í„° í¬ê¸°: 17693331\n"," - 1ë¶„ êµ¬ê°„ ê°œìˆ˜: 19646\n"," - ê° êµ¬ê°„ í‰ê·  ë°ì´í„° ê°œìˆ˜: 900.56\n","\n","[Folder 3] ì†¡í˜„\n"," - ì „ì²´ ë°ì´í„° í¬ê¸°: 11261135\n"," - 1ë¶„ êµ¬ê°„ ê°œìˆ˜: 76283\n"," - ê° êµ¬ê°„ í‰ê·  ë°ì´í„° ê°œìˆ˜: 147.61\n","\n","ëª¨ë“  í´ë” ì²˜ë¦¬ ì™„ë£Œ!\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import scipy.signal as signal\n","import sys\n","import warnings\n","\n","sys.path.append('/content/HRV')  # HRV ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€\n","\n","# ë¶ˆí•„ìš”í•œ ê²½ê³  ì œê±°\n","warnings.simplefilter(\"ignore\", UserWarning)\n","\n","# Matplotlib ì„¤ì • (í°íŠ¸ ë¬¸ì œ ë°©ì§€)\n","plt.rcParams['font.family'] = 'sans-serif'\n","plt.rcParams['axes.unicode_minus'] = False\n","\n","# HRV ëª¨ë“ˆ import\n","from timeDomain import timeDomain\n","from frequencyDomain import frequencyDomain\n","\n","# ì‚¬ìš©ì ì´ë¦„\n","user_name = \"ê°•í˜„ìŠ¹\"\n","\n","# ===================================================================\n","# ----------------- 1. PPG ë°ì´í„° ë¡œë”© ë¶€ë¶„ -------------------------\n","# ===================================================================\n","data_path = \"/content/drive/MyDrive/RA/[wearable] á„€á…ªá„Œá…¦/HRV á„‡á…®á†«á„‰á…¥á†¨/Datas/á„†á…©á„‡á…¡á„‹á…µá†¯ á„ƒá…¦á„‹á…µá„á…¥/á„€á…¡á†¼á„’á…§á†«á„‰á…³á†¼\"\n","sensor_data = {}\n","sensor_configs = {'PpgGreen': ['time', 'value']}\n","\n","try:\n","    for sensor, columns in sensor_configs.items():\n","        sensor_files = [f for f in os.listdir(data_path) if f.startswith(sensor)]\n","        data_frames = []\n","        for file in sensor_files:\n","            file_path = os.path.join(data_path, file)\n","            try:\n","                df_tmp = pd.read_csv(file_path, names=columns, header=0)\n","                data_frames.append(df_tmp)\n","            except Exception as e:\n","                print(f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file} - {e}\")\n","        if data_frames:\n","            sensor_data[sensor] = pd.concat(data_frames, ignore_index=True)\n","\n","except Exception as e:\n","    print(f\"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}\")\n","    sys.exit(1)\n","\n","if 'PpgGreen' not in sensor_data:\n","    print(\"âŒ PpgGreen ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n","    sys.exit(1)\n","\n","df = sensor_data['PpgGreen']\n","print(f\"âœ… ë¡œë“œëœ PpgGreen ë°ì´í„° í¬ê¸°: {df.shape}\")\n","\n","# ì‹œê°„ ë³€í™˜ ë° ì •ë ¬\n","try:\n","    df['time'] = pd.to_datetime(df['time'], unit='ms')\n","    df = df.sort_values(by='time').reset_index(drop=True)\n","except Exception as e:\n","    print(f\"âŒ ì‹œê°„ ë³€í™˜ ì˜¤ë¥˜: {e}\")\n","    sys.exit(1)\n","\n","# ===================================================================\n","# ----------------- 2. ì „ì²´ 1ë¶„ êµ¬ê°„ ë°˜ë³µ ì„¤ì • ----------------------\n","# ===================================================================\n","min_time = df['time'].min()\n","max_time = df['time'].max()\n","\n","chunk_duration = pd.Timedelta(seconds=60)\n","\n","# ê²°ê³¼ ì €ì¥ í´ë” (ì´ë¯¸ì§€ ë“±)\n","output_dir = \"./preprocessing\"\n","os.makedirs(output_dir, exist_ok=True)\n","img_dir = os.path.join(output_dir, \"images\")\n","os.makedirs(img_dir, exist_ok=True)\n","\n","results = []  # CSVë¡œ ë‚´ë³´ë‚¼ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ (ê° rowë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ)\n","\n","current_start = min_time\n","while True:\n","    current_end = current_start + chunk_duration\n","    if current_end > max_time:\n","        break  # ë” ì´ìƒ 1ë¶„ êµ¬ê°„ì„ ë§Œë“¤ ìˆ˜ ì—†ìœ¼ë©´ ì¢…ë£Œ\n","\n","    filtered_df = df[(df['time'] >= current_start) & (df['time'] < current_end)].copy()\n","    data_count = len(filtered_df)\n","\n","    if data_count < 500:\n","        results.append({\n","            \"start_time\": current_start,\n","            \"end_time\": current_end,\n","            \"data_count\": data_count,\n","            \"peak_count\": None,\n","            \"rr_count\": None,\n","            \"sqi\": None,\n","            \"noise_ratio\": None,\n","            # Time/Freq Domain\n","            \"ANN\": None, \"SDNN\": None, \"SDSD\": None,\n","            \"NN50\": None, \"pNN50\": None, \"NN20\": None,\n","            \"pNN20\": None, \"rMSSD\": None, \"MedianNN\": None,\n","            \"VLF_Power\": None, \"LF_Power\": None,\n","            \"HF_Power\": None, \"LF_HF\": None,\n","            # detail_dict\n","            \"sigma_noise_ratio\": None,\n","            \"hist_noise_ratio\": None,\n","            \"ellipse_noise_ratio\": None,\n","            \"varrange_noise_ratio\": None,\n","            \"amplitude_noise_ratio\": None,\n","            \"peakcount_noise_ratio\": None,\n","            # ê·¸ë˜í”„ ê²½ë¡œ\n","            \"raw_plot_path\": None,\n","            \"filtered_plot_path\": None,\n","            \"freq_plot_path\": None\n","        })\n","        current_start = current_end\n","        continue\n","\n","    # ===================================================================\n","    # ----------------- 3. í•„í„°ë§ ë° í”¼í¬ ê²€ì¶œ --------------------------\n","    # ===================================================================\n","    def bandpass_filter(data, fs, lowcut=0.5, highcut=5.0, order=2):\n","        nyq = 0.5 * fs\n","        low = lowcut / nyq\n","        high = highcut / nyq\n","        b, a = signal.butter(order, [low, high], btype='band')\n","        return signal.filtfilt(b, a, data)\n","\n","    fs = 25\n","    filtered_df['filtered'] = bandpass_filter(filtered_df['value'], fs)\n","\n","    min_distance = int(0.5 * fs)\n","    peaks, _ = signal.find_peaks(filtered_df['filtered'], distance=min_distance)\n","    peak_count = len(peaks)\n","\n","    if peak_count < 5:\n","        results.append({\n","            \"start_time\": current_start,\n","            \"end_time\": current_end,\n","            \"data_count\": data_count,\n","            \"peak_count\": peak_count,\n","            \"rr_count\": None,\n","            \"sqi\": None,\n","            \"noise_ratio\": None,\n","            # Time/Freq Domain\n","            \"ANN\": None, \"SDNN\": None, \"SDSD\": None,\n","            \"NN50\": None, \"pNN50\": None, \"NN20\": None,\n","            \"pNN20\": None, \"rMSSD\": None, \"MedianNN\": None,\n","            \"VLF_Power\": None, \"LF_Power\": None,\n","            \"HF_Power\": None, \"LF_HF\": None,\n","            # detail_dict\n","            \"sigma_noise_ratio\": None,\n","            \"hist_noise_ratio\": None,\n","            \"ellipse_noise_ratio\": None,\n","            \"varrange_noise_ratio\": None,\n","            \"amplitude_noise_ratio\": None,\n","            \"peakcount_noise_ratio\": None,\n","            # ê·¸ë˜í”„ ê²½ë¡œ\n","            \"raw_plot_path\": None,\n","            \"filtered_plot_path\": None,\n","            \"freq_plot_path\": None\n","        })\n","        current_start = current_end\n","        continue\n","\n","    # ===================================================================\n","    # ----------------- 4. RR intervals & ë…¸ì´ì¦ˆ(SQI) ê³„ì‚° --------------\n","    # ===================================================================\n","    peak_times = filtered_df['time'].iloc[peaks].values\n","    rr_intervals = np.diff(peak_times) / np.timedelta64(1, 's')\n","    rr_count = len(rr_intervals)\n","\n","    if rr_count < 5:\n","        results.append({\n","            \"start_time\": current_start,\n","            \"end_time\": current_end,\n","            \"data_count\": data_count,\n","            \"peak_count\": peak_count,\n","            \"rr_count\": rr_count,\n","            \"sqi\": None,\n","            \"noise_ratio\": None,\n","            # Time/Freq Domain\n","            \"ANN\": None, \"SDNN\": None, \"SDSD\": None,\n","            \"NN50\": None, \"pNN50\": None, \"NN20\": None,\n","            \"pNN20\": None, \"rMSSD\": None, \"MedianNN\": None,\n","            \"VLF_Power\": None, \"LF_Power\": None,\n","            \"HF_Power\": None, \"LF_HF\": None,\n","            # detail_dict\n","            \"sigma_noise_ratio\": None,\n","            \"hist_noise_ratio\": None,\n","            \"ellipse_noise_ratio\": None,\n","            \"varrange_noise_ratio\": None,\n","            \"amplitude_noise_ratio\": None,\n","            \"peakcount_noise_ratio\": None,\n","            # ê·¸ë˜í”„ ê²½ë¡œ\n","            \"raw_plot_path\": None,\n","            \"filtered_plot_path\": None,\n","            \"freq_plot_path\": None\n","        })\n","        current_start = current_end\n","        continue\n","\n","    # >>> SQI ê³„ì‚° (detail_dict í¬í•¨í•´ì„œ 3ê°œ ì–¸íŒ¨í‚¹)\n","    sqi, noise_ratio, detail_dict = calculate_SQI(rr_intervals=rr_intervals,\n","                                                 ppg_signal=filtered_df['filtered'],\n","                                                 peak_count=peak_count)\n","\n","    # ===================================================================\n","    # ----------------- 5. HRV ë¶„ì„ (ì‹œê°„ & ì£¼íŒŒìˆ˜) ---------------------\n","    # ===================================================================\n","    try:\n","        timeDomainFeats = timeDomain(rr_intervals)\n","        freqDomainFeats = frequencyDomain(rr_intervals, plot=0)\n","    except Exception as e:\n","        print(f\"âŒ HRV ë¶„ì„ ì˜¤ë¥˜: {e}\")\n","        timeDomainFeats, freqDomainFeats = {}, {}\n","\n","    # ===================================================================\n","    # ----------------- 6. ê·¸ë˜í”„ ì €ì¥ (raw, filtered, freq) ------------\n","    # ===================================================================\n","    raw_fig, raw_ax = plt.subplots(figsize=(12, 4))\n","    raw_ax.plot(filtered_df['time'], filtered_df['value'], label='Raw PpgGreen', color='blue')\n","    raw_ax.set_title(f\"Raw PpgGreen (Interval: {current_start} ~ {current_end})\")\n","    raw_ax.set_xlabel(\"Time\")\n","    raw_ax.set_ylabel(\"PPG Value\")\n","    raw_ax.legend()\n","\n","    raw_plot_name = f\"chunk_{current_start.strftime('%Y%m%d_%H%M%S')}_raw.png\"\n","    raw_plot_path = os.path.join(img_dir, raw_plot_name)\n","    plt.savefig(raw_plot_path)\n","    plt.close(raw_fig)\n","\n","    filt_fig, filt_ax = plt.subplots(figsize=(12, 4))\n","    filt_ax.plot(filtered_df['time'], filtered_df['filtered'], label='Filtered PpgGreen', color='green')\n","    filt_ax.scatter(filtered_df['time'].iloc[peaks], filtered_df['filtered'].iloc[peaks],\n","                    color='red', label='Detected Peaks')\n","    filt_ax.set_title(f\"Filtered + Peaks (Interval: {current_start} ~ {current_end})\")\n","    filt_ax.set_xlabel(\"Time\")\n","    filt_ax.set_ylabel(\"PPG Value\")\n","    filt_ax.legend()\n","\n","    filtered_plot_name = f\"chunk_{current_start.strftime('%Y%m%d_%H%M%S')}_filtered.png\"\n","    filtered_plot_path = os.path.join(img_dir, filtered_plot_name)\n","    plt.savefig(filtered_plot_path)\n","    plt.close(filt_fig)\n","\n","    freq_fig = plt.figure(figsize=(8, 4))\n","    f, pxx = signal.welch(rr_intervals, fs=1.0, nperseg=len(rr_intervals))\n","    plt.semilogy(f, pxx, label='RR Spectrum')\n","    plt.title(f\"Frequency Domain (Interval: {current_start} ~ {current_end})\")\n","    plt.xlabel(\"Frequency (Hz)\")\n","    plt.ylabel(\"PSD\")\n","    plt.legend()\n","\n","    freq_plot_name = f\"chunk_{current_start.strftime('%Y%m%d_%H%M%S')}_freq.png\"\n","    freq_plot_path = os.path.join(img_dir, freq_plot_name)\n","    plt.savefig(freq_plot_path)\n","    plt.close(freq_fig)\n","\n","    # ===================================================================\n","    # ----------------- 7. CSV ê²°ê³¼ìš© ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ ----------------------\n","    # ===================================================================\n","    ANN_val = timeDomainFeats.get('ANN')\n","    SDNN_val = timeDomainFeats.get('SDNN')\n","    SDSD_val = timeDomainFeats.get('SDSD')\n","    NN50_val = timeDomainFeats.get('NN50')\n","    pNN50_val = timeDomainFeats.get('pNN50')\n","    NN20_val = timeDomainFeats.get('NN20')\n","    pNN20_val = timeDomainFeats.get('pNN20')\n","    rMSSD_val = timeDomainFeats.get('rMSSD')\n","    MedianNN_val = timeDomainFeats.get('MedianNN')\n","\n","    VLF_val = freqDomainFeats.get('VLF_Power')\n","    LF_val = freqDomainFeats.get('LF_Power')\n","    HF_val = freqDomainFeats.get('HF_Power')\n","    LF_HF_val = freqDomainFeats.get('LF/HF')\n","\n","    row_dict = {\n","        \"start_time\": current_start,\n","        \"end_time\": current_end,\n","        \"data_count\": data_count,\n","        \"peak_count\": peak_count,\n","        \"rr_count\": rr_count,\n","        \"sqi\": sqi,\n","        \"noise_ratio\": noise_ratio,\n","        # Time Domain\n","        \"ANN\": ANN_val,\n","        \"SDNN\": SDNN_val,\n","        \"SDSD\": SDSD_val,\n","        \"NN50\": NN50_val,\n","        \"pNN50\": pNN50_val,\n","        \"NN20\": NN20_val,\n","        \"pNN20\": pNN20_val,\n","        \"rMSSD\": rMSSD_val,\n","        \"MedianNN\": MedianNN_val,\n","        # Freq Domain\n","        \"VLF_Power\": VLF_val,\n","        \"LF_Power\": LF_val,\n","        \"HF_Power\": HF_val,\n","        \"LF_HF\": LF_HF_val,\n","        # detail_dict (ë…¸ì´ì¦ˆ ê¸°ë²•ë³„ ì„¸ë¶€ ì§€í‘œ)\n","        \"sigma_noise_ratio\": detail_dict.get(\"sigma_noise_ratio\"),\n","        \"hist_noise_ratio\": detail_dict.get(\"hist_noise_ratio\"),\n","        \"ellipse_noise_ratio\": detail_dict.get(\"ellipse_noise_ratio\"),\n","        \"varrange_noise_ratio\": detail_dict.get(\"varrange_noise_ratio\"),\n","        \"amplitude_noise_ratio\": detail_dict.get(\"amplitude_noise_ratio\"),\n","        \"peakcount_noise_ratio\": detail_dict.get(\"peakcount_noise_ratio\"),\n","        # ê·¸ë˜í”„ ê²½ë¡œ\n","        \"raw_plot_path\": raw_plot_path,\n","        \"filtered_plot_path\": filtered_plot_path,\n","        \"freq_plot_path\": freq_plot_path\n","    }\n","    results.append(row_dict)\n","\n","    current_start = current_end\n","\n","# ===================================================================\n","# ----------------- 8. CSV íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥ -------------------------\n","# ===================================================================\n","results_df = pd.DataFrame(results)\n","\n","# â–¼â–¼ CSV ì €ì¥ ê²½ë¡œë¥¼ ì‚¬ìš©ì ìš”ì²­ëŒ€ë¡œ ë³€ê²½ â–¼â–¼\n","csv_path = f\"/content/drive/MyDrive/RA/[wearable] á„€á…ªá„Œá…¦/HRV á„‡á…®á†«á„‰á…¥á†¨/Datas/preprocessing/{user_name}[{min_time} ~ {max_time}].csv\"\n","results_df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n","\n","print(f\"\\nâœ… ëª¨ë“  1ë¶„ êµ¬ê°„ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ CSV: {csv_path}\")\n","print(f\"âœ… ê·¸ë˜í”„ ì´ë¯¸ì§€ëŠ” {img_dir} í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"],"metadata":{"id":"Sx10m-5DKbI3","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1741759806199,"user_tz":-540,"elapsed":17,"user":{"displayName":"sangtaek lim","userId":"15090029148866172998"}},"outputId":"7fcb9467-8a19-4280-dd26-dc85f5d4cd60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: [Errno 2] No such file or directory: '/content/drive/MyDrive/RA/[wearable] á„€á…ªá„Œá…¦/HRV á„‡á…®á†«á„‰á…¥á†¨/Datas/á„†á…©á„‡á…¡á„‹á…µá†¯ á„ƒá…¦á„‹á…µá„á…¥/á„€á…¡á†¼á„’á…§á†«á„‰á…³á†¼'\n","Traceback (most recent call last):\n","  File \"<ipython-input-17-cce521a650a6>\", line 34, in <cell line: 0>\n","    sensor_files = [f for f in os.listdir(data_path) if f.startswith(sensor)]\n","                               ^^^^^^^^^^^^^^^^^^^^^\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/RA/[wearable] á„€á…ªá„Œá…¦/HRV á„‡á…®á†«á„‰á…¥á†¨/Datas/á„†á…©á„‡á…¡á„‹á…µá†¯ á„ƒá…¦á„‹á…µá„á…¥/á„€á…¡á†¼á„’á…§á†«á„‰á…³á†¼'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-17-cce521a650a6>\", line 48, in <cell line: 0>\n","    sys.exit(1)\n","SystemExit: 1\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n","    traceback_info = getframeinfo(tb, context)\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1671, in getframeinfo\n","    lineno = frame.f_lineno\n","             ^^^^^^^^^^^^^^\n","AttributeError: 'tuple' object has no attribute 'f_lineno'\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-cce521a650a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msensor_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0msensor_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mdata_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/RA/[wearable] á„€á…ªá„Œá…¦/HRV á„‡á…®á†«á„‰á…¥á†¨/Datas/á„†á…©á„‡á…¡á„‹á…µá†¯ á„ƒá…¦á„‹á…µá„á…¥/á„€á…¡á†¼á„’á…§á†«á„‰á…³á†¼'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-17-cce521a650a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemExit\u001b[0m: 1","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9rZjRzn8mJrk"},"execution_count":null,"outputs":[]}]}